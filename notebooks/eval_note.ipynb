{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f1cef4",
   "metadata": {},
   "source": [
    "# Evaluating Memory Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d105c",
   "metadata": {},
   "outputs": [],
   "source": "# Add project root to Python path to enable src imports\nimport sys\nimport os\nsys.path.append(os.path.join(os.getcwd(), '..'))\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom src.synthetic_datasets import BatchedInContextRecallDataset\nfrom src.meta_optimizers import MetaSGD\nfrom src.memory_module import inner_optimization_forward, TTT\nfrom src.evaluate import (\n    compute_recall_accuracies, \n    correct_retrieval_counts_by_timestep, \n    average_accuracy_by_offset\n)\nfrom src.linear_RNN import LinearAttentionMemory, MesaLayerMemory"
  },
  {
   "cell_type": "markdown",
   "id": "eff4553b",
   "metadata": {},
   "source": [
    "## Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a47e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dim=10\n",
    "val_dim=10\n",
    "context_size=5 # inner loss computation window\n",
    "seq_len=30\n",
    "batch_size=500\n",
    "output_corr=0\n",
    "inner_optimizer=MetaSGD()\n",
    "#inner_optimizer_kwargs={ \"beta\": torch.tensor(0.9)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c616e",
   "metadata": {},
   "source": [
    "## Forward pass and recall accuracy computation\n",
    "For the recall accuracy computation, we organize the accuracy by offset. If our current memory module is $m_t$ at time $t$, we evaluate it to see whether $i=\\arg\\max_{j\\in[t]}(m_t(k_i),v_j)$ for all $i\\in[t]$. So accuracy at offset $s$ is computing whether $ t-s=\\arg\\max_{j\\in[t]}(m_t(k_{t-s}),v_j)$ as $t$ varies across $[s,\\text{seq\\_len}]$. Note that as $s$ gets larger, there are fewer samples, so the results are not as reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbd688",
   "metadata": {},
   "outputs": [],
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndataset = BatchedInContextRecallDataset(\n    seq_len=seq_len,\n    key_dim=key_dim,\n    val_dim=val_dim,\n    context_size=context_size,\n    batch_size=batch_size,\n)\n\nlearning_rates = [0.05, 0.1, 0.2]\nrecall_acc = {}\nretrieval_counts = {}\n\nfor lr in learning_rates:\n\n    _, predictions = inner_optimization_forward(\n        memory_module=TTT(key_dim, val_dim, 1, 0.0).to(device),\n        dataset=dataset.to(device),\n        inner_opt=inner_optimizer,\n        lr_head=lr,\n        loss_weight_head=torch.ones(context_size).to(device),\n        eval_mode=True\n    )\n\n    accuracies = compute_recall_accuracies(\n        predictions, dataset.targets)\n    accuracy_by_offset, count = average_accuracy_by_offset(accuracies)\n    retrieval_count = correct_retrieval_counts_by_timestep(accuracies)\n\n    # Store results\n    recall_acc[lr] = accuracy_by_offset.to(\"cpu\")\n    retrieval_counts[lr] = retrieval_count.to(\"cpu\")\n\n# linear attention\nstate = LinearAttentionMemory.init_state(\n    batch_size, val_dim, key_dim).to(device)\npredictions = []\n\n# mesa layer attention\ngamma = torch.tensor(1)\nmesa_memory = MesaLayerMemory(key_dim, val_dim)\nR_matrix, S_matrix, phi_matrix = mesa_memory.init_state(batch_size)\nmesa_predictions = []\n\nkeys = dataset.inputs            # (B, seq_len, key_dim)\nvalues = dataset.targets         # (B, seq_len, val_dim)\n\nfor t in range(seq_len):\n    key_t = keys[:, t]         # (B, key_dim)\n    value_t = values[:, t]      # (B, val_dim)\n\n    # update state\n    state = LinearAttentionMemory.update(state, key_t, value_t)\n\n    prefix_keys = keys[:, :t+1]          # (B, t+1, key_dim)\n    preds_t = LinearAttentionMemory.forward(\n        state, prefix_keys)  # (B, t+1, val_dim)\n    predictions.append(preds_t)\n\n    # mesa layer\n    R_matrix, S_matrix, phi_matrix = mesa_memory.update(\n        R_matrix, S_matrix, phi_matrix, key_t, value_t, gamma)\n\n    mesa_preds_t = mesa_memory.forward(phi_matrix, prefix_keys)\n    mesa_predictions.append(mesa_preds_t)\n\nlin_attn_accuracy_history = compute_recall_accuracies(\n    predictions, values)\nlin_attn_accuracy_by_offset, _ = average_accuracy_by_offset(\n    lin_attn_accuracy_history)\nlin_attn_accuracy_by_offset = lin_attn_accuracy_by_offset.to(\"cpu\")\n\nmesa_acc_history = compute_recall_accuracies(\n    mesa_predictions, values)\nmesa_acc_by_offset, _ = average_accuracy_by_offset(mesa_acc_history)\nmesa_acc_by_offset = mesa_acc_by_offset.to(\"cpu\")\n\nplt.figure(figsize=(10, 6))\n\n# Define colors and line styles for each learning rate\ncolors = ['blue', 'red', 'green', 'purple']\nline_styles = ['-', '--', '-.', ':']\n\nplot_configs = []\nfor i, lr in enumerate(learning_rates):\n    plot_configs.append({\n        \"label\": f'TTT Model (lr={lr})',\n        \"values\": recall_acc[lr],\n        \"color\": colors[i],\n        \"linestyle\": line_styles[i]\n    })\n\nplot_configs.extend([\n    {\n        \"label\": \"Linear Attention\",\n        \"values\": lin_attn_accuracy_by_offset,\n        \"color\": \"orange\",\n        \"linestyle\": \"-\",\n    },\n    {\n        \"label\": \"Mesa Attention\",\n        \"values\": mesa_acc_by_offset,\n        \"color\": \"purple\",\n        \"linestyle\": \"-\",\n    },\n])\n\nfor config in plot_configs:\n    offsets = np.arange(len(config[\"values\"]))\n    plt.plot(\n        offsets,\n        config[\"values\"],\n        color=config[\"color\"],\n        linestyle=config[\"linestyle\"],\n        linewidth=2,\n        label=config[\"label\"],\n    )\n\n# Plot average accuracy by offset\nplt.xlabel(\"Offset (0 = current timestep)\", fontsize=12)\nplt.ylabel(\"Recall accuracy\", fontsize=12)\nplt.title(\"Recall accuracy by offset\", fontsize=14, fontweight='bold')\nplt.ylim(0.0, 1.05)\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "f8c64625",
   "metadata": {},
   "source": [
    "## Retrieval Counts by Timestep\n",
    "Here we plot the number of correct retrievals $i=\\arg\\max_{j\\in[t]}(m_t(k_i),v_j)$ for all $i\\in[t]$. If the memory module could retieve all the key value pairs its seen perfectly, we would see the line $y=x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067024d",
   "metadata": {},
   "outputs": [],
   "source": "# Plot retrieval counts by timestep\nplt.figure(figsize=(12, 6))\n\n# Define colors and line styles for each learning rate\ncolors = ['blue', 'red', 'green', 'purple']\nline_styles = ['-', '--', '-.', ':']\n\nlin_attn_retrieval_count = correct_retrieval_counts_by_timestep(\n    lin_attn_accuracy_history).to(\"cpu\")\nmesa_retrieval_count = correct_retrieval_counts_by_timestep(\n    mesa_acc_history).to(\"cpu\")\n\nretrieval_plot_configs = []\nfor i, lr in enumerate(learning_rates):\n    retrieval_plot_configs.append({\n        \"label\": f'LR={lr}',\n        \"values\": retrieval_counts[lr],\n        \"color\": colors[i],\n        \"linestyle\": line_styles[i]\n    })\n\nretrieval_plot_configs.extend([\n    {\n        \"label\": \"Linear Attention\",\n        \"values\": lin_attn_retrieval_count,\n        \"color\": \"orange\",\n        \"linestyle\": \"-\",\n    },\n    {\n        \"label\": \"Mesa Attention\",\n        \"values\": mesa_retrieval_count,\n        \"color\": \"purple\",\n        \"linestyle\": \"-\",\n    },\n])\n\nfor config in retrieval_plot_configs:\n    timesteps = np.arange(len(config[\"values\"]))\n    plt.plot(\n        timesteps,\n        config[\"values\"],\n        color=config[\"color\"],\n        linestyle=config[\"linestyle\"],\n        linewidth=2,\n        label=config[\"label\"],\n    )\n\nplt.xlabel(\"Timestep\", fontsize=12)\nplt.ylabel(\"Correct retrieval count\", fontsize=12)\nplt.title(\"Correct retrieval counts by timestep\", \n          fontsize=14, fontweight='bold')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}