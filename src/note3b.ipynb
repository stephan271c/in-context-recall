{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fd42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Iteration: 10, Avg Outer Loss: 1.0258\n",
      "Outer Iteration: 20, Avg Outer Loss: 1.0253\n",
      "Outer Iteration: 30, Avg Outer Loss: 1.0248\n",
      "Outer Iteration: 40, Avg Outer Loss: 1.0242\n",
      "Outer Iteration: 50, Avg Outer Loss: 1.0237\n",
      "Outer Iteration: 60, Avg Outer Loss: 1.0230\n",
      "Outer Iteration: 70, Avg Outer Loss: 1.0225\n",
      "Outer Iteration: 80, Avg Outer Loss: 1.0219\n",
      "Outer Iteration: 90, Avg Outer Loss: 1.0214\n",
      "Outer Iteration: 100, Avg Outer Loss: 1.0208\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchopt\n",
    "\n",
    "# Define the dimensions of the vectors\n",
    "key_dim = 10\n",
    "val_dim = 10\n",
    "hidden_dim = 20\n",
    "context_dim = 5\n",
    "\n",
    "# Define the two neural networks, f and g\n",
    "class F_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(key_dim + hidden_dim, 8)\n",
    "        self.fc2 = nn.Linear(8, val_dim)\n",
    "\n",
    "    def forward(self, key, g_out):\n",
    "        x = torch.cat([key, g_out], dim=-1)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class G_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(key_dim, context_dim)\n",
    "        self.fc2 = nn.Linear(context_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, key):\n",
    "        x = F.sigmoid(self.fc1(key))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Instantiate the networks\n",
    "f_net = F_Net() # inner loop network. depends on g_net which only updates in the outer loop\n",
    "g_net = G_Net()\n",
    "\n",
    "# Define the meta-optimizer for the inner loop (f_net)\n",
    "inner_optimizer = torchopt.MetaAdam(f_net, lr=1e-3)\n",
    "\n",
    "# Define the optimizer for the outer loop (g_net)\n",
    "outer_optimizer = torch.optim.Adam(g_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the loss functions\n",
    "inner_loss_fn = nn.MSELoss()\n",
    "outer_loss_fn = lambda pred, target: 1 - F.cosine_similarity(pred, target).mean()\n",
    "\n",
    "# --- Training Loop ---\n",
    "\n",
    "# Generate a sequence of dummy data\n",
    "num_steps = 5\n",
    "batch_size = 4\n",
    "sequence_of_keys = [torch.randn(batch_size, key_dim) for _ in range(num_steps)]\n",
    "sequence_of_vals = [torch.randn(batch_size, val_dim) for _ in range(num_steps)]\n",
    "\n",
    "# We need to save the initial state of f_net to reset it for each outer loop iteration\n",
    "f_net_initial_state = torchopt.extract_state_dict(f_net)\n",
    "inner_optim_initial_state = torchopt.extract_state_dict(inner_optimizer)\n",
    "\n",
    "# Number of outer loop iterations\n",
    "for outer_iter in range(100):\n",
    "    # Reset f_net to its initial state before each outer loop\n",
    "    torchopt.recover_state_dict(f_net, f_net_initial_state)\n",
    "    torchopt.recover_state_dict(inner_optimizer, inner_optim_initial_state)\n",
    "    \n",
    "    outer_optimizer.zero_grad()\n",
    "\n",
    "    # --- CHANGE 1: Initialize total outer loss for the sequence ---\n",
    "    total_outer_loss = torch.tensor(0.0)\n",
    "\n",
    "    # --- Inner Loop ---\n",
    "    for i in range(num_steps):\n",
    "        key = sequence_of_keys[i]\n",
    "        val = sequence_of_vals[i]\n",
    "\n",
    "        # --- Part 1: Inner Loop Update ---\n",
    "        # This part builds the differentiable update rule for f_net\n",
    "        g_output = g_net(key)\n",
    "        f_output = f_net(key, g_output)\n",
    "        inner_loss = inner_loss_fn(f_output, val)\n",
    "        inner_optimizer.step(inner_loss)\n",
    "\n",
    "        # --- Part 2: Outer Loss Calculation ---\n",
    "        # This part evaluates the updated f_net and connects the outer loss\n",
    "        # back to g_net. It MUST be done with gradients enabled.\n",
    "        \n",
    "        # We use the *updated* f_net to make a prediction.\n",
    "        # The g_output tensor here will carry the gradients back to g_net.\n",
    "        f_output_after_update = f_net(key, g_net(key)) # why do we use a different name here?\n",
    "        \n",
    "        # Calculate the outer loss for the current step\n",
    "        step_outer_loss = outer_loss_fn(f_output_after_update, val)\n",
    "        \n",
    "        # Add it to the total outer loss for the sequence\n",
    "        total_outer_loss = total_outer_loss + step_outer_loss\n",
    "\n",
    "\n",
    "    # --- Outer Loop Loss Calculation and Update ---\n",
    "\n",
    "    # --- CHANGE 3: Backpropagate the accumulated outer loss ---\n",
    "    # This will compute gradients for g_net's parameters from all steps.\n",
    "    # We also need to normalize the loss by the number of steps to keep the gradient magnitude stable\n",
    "    final_outer_loss = total_outer_loss / num_steps\n",
    "    final_outer_loss.backward()\n",
    "\n",
    "    # Update g_net's parameters\n",
    "    outer_optimizer.step()\n",
    "\n",
    "    if (outer_iter + 1) % 10 == 0:\n",
    "        # --- CHANGE 4: Print the averaged outer loss ---\n",
    "        print(f\"Outer Iteration: {outer_iter + 1}, Avg Outer Loss: {final_outer_loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
