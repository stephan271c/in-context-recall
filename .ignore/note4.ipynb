{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7305ccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Loss Weights: tensor([0.3706, 0.4795, 0.6065, 0.4579, 0.4516], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 0, Step 50, Loss Weights: tensor([0.5511, 0.3821, 0.5415, 0.5142, 0.7165], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 0, Outer Loss: 4.188896656036377\n",
      "Epoch 10, Step 0, Loss Weights: tensor([0.4109, 0.2953, 0.3787, 0.6504, 0.7293], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 10, Step 50, Loss Weights: tensor([0.4633, 0.4141, 0.5108, 0.5672, 0.6180], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 10, Outer Loss: 4.134033679962158\n",
      "Epoch 20, Step 0, Loss Weights: tensor([0.2572, 0.4298, 0.5219, 0.7240, 0.6554], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 20, Step 50, Loss Weights: tensor([0.2516, 0.2383, 0.5506, 0.7069, 0.7413], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 20, Outer Loss: 4.033472061157227\n",
      "Epoch 30, Step 0, Loss Weights: tensor([0.2045, 0.1867, 0.2012, 0.8190, 0.7957], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 30, Step 50, Loss Weights: tensor([0.1665, 0.1707, 0.3483, 0.7525, 0.7909], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 30, Outer Loss: 4.001039505004883\n",
      "Epoch 40, Step 0, Loss Weights: tensor([0.1062, 0.1114, 0.1911, 0.8224, 0.8614], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 40, Step 50, Loss Weights: tensor([0.1341, 0.1247, 0.2599, 0.8623, 0.8548], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 40, Outer Loss: 3.9466745853424072\n",
      "Epoch 50, Step 0, Loss Weights: tensor([0.0840, 0.0818, 0.1127, 0.8888, 0.8922], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 50, Step 50, Loss Weights: tensor([0.0713, 0.0931, 0.1329, 0.8711, 0.9057], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 50, Outer Loss: 3.91740345954895\n",
      "Epoch 60, Step 0, Loss Weights: tensor([0.0798, 0.0661, 0.0806, 0.8901, 0.9054], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 60, Step 50, Loss Weights: tensor([0.0791, 0.0595, 0.1084, 0.8947, 0.9104], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 60, Outer Loss: 3.93280029296875\n",
      "Epoch 70, Step 0, Loss Weights: tensor([0.0479, 0.0444, 0.0546, 0.9248, 0.9387], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 70, Step 50, Loss Weights: tensor([0.0497, 0.0497, 0.0492, 0.9171, 0.9367], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 70, Outer Loss: 3.920891523361206\n",
      "Epoch 80, Step 0, Loss Weights: tensor([0.0424, 0.0385, 0.0484, 0.9265, 0.9418], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 80, Step 50, Loss Weights: tensor([0.0372, 0.0324, 0.0504, 0.9246, 0.9403], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 80, Outer Loss: 3.89760160446167\n",
      "Epoch 90, Step 0, Loss Weights: tensor([0.0354, 0.0291, 0.0321, 0.9353, 0.9530], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 90, Step 50, Loss Weights: tensor([0.0276, 0.0240, 0.0338, 0.9363, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 90, Outer Loss: 3.8683457374572754\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchopt\n",
    "\n",
    "from losses import windowed_p_loss\n",
    "from func_memory_module import LinearModel, TTTMLP, WeightModel\n",
    "from synthetic_datasets import InContextRecallDataset\n",
    "\n",
    "# USING TORCHOPT FOR META-LEARNING\n",
    "# Define the dimensions of the vectors\n",
    "key_dim = 10\n",
    "val_dim = 10\n",
    "hidden_dim = 20\n",
    "context_dim = 5\n",
    "\n",
    "# instantiate models\n",
    "weight_model = WeightModel(key_dim, context_dim)\n",
    "memory_module= TTTMLP(key_dim, val_dim)\n",
    "\n",
    "# instantiate optimizers\n",
    "inner_optimizer = torchopt.MetaSGD(memory_module, lr=0.3)\n",
    "outer_optimizer = torch.optim.AdamW(weight_model.parameters(), lr=0.05)\n",
    "\n",
    "#define loss function\n",
    "inner_loss_func = windowed_p_loss\n",
    "outer_loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "seq_len = 100\n",
    "\n",
    "# save initial state\n",
    "memory_module_init = torchopt.extract_state_dict(memory_module)\n",
    "inner_optimizer_init = torchopt.extract_state_dict(inner_optimizer)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Generate a new sequence of keys and values for each epoch\n",
    "    my_dataset = InContextRecallDataset(seq_len=seq_len, key_dim=key_dim, val_dim=val_dim, context_size=context_dim, output_corr=0.5)\n",
    "\n",
    "    _, val_vectors = my_dataset[:]\n",
    "\n",
    "    # Reset model and optimizer to initial state\n",
    "    torchopt.recover_state_dict(memory_module, memory_module_init)\n",
    "    torchopt.recover_state_dict(inner_optimizer, inner_optimizer_init)\n",
    "\n",
    "    outer_optimizer.zero_grad()\n",
    "    total_outer_loss = torch.tensor(0.0)\n",
    "\n",
    "    # inner loop\n",
    "    for i in range(seq_len):\n",
    "        input, output = my_dataset[i]\n",
    "        loss_weights = weight_model(input[-1]) # should only rely on current key in context\n",
    "        if epoch % 10 == 0 and i % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Step {i}, Loss Weights: {loss_weights}\")\n",
    "        pred = memory_module(input)\n",
    "\n",
    "        inner_loss = inner_loss_func(pred.T, output.T, loss_weights) # the loss has a transposed shape\n",
    "        inner_optimizer.step(inner_loss)\n",
    "\n",
    "        pred_after_update = memory_module(input[-1]) #now shape (1, val_dim) (we only take the last one.)\n",
    "        #print(pred_after_update.shape, val_vectors.T.shape)\n",
    "        logits = torch.matmul(pred_after_update, val_vectors.T) # shape (1, seq_len)\n",
    "        target_index = torch.tensor([i], dtype=torch.long) # shape (1,)\n",
    "        #print(temp.shape , target_index.shape, logits.shape)\n",
    "        #print(temp.dtype , target_index.dtype)\n",
    "        outer_loss_step = outer_loss_func(logits, target_index)\n",
    "        total_outer_loss += outer_loss_step\n",
    "    \n",
    "    # outer loop calculation\n",
    "    final_outer_loss = total_outer_loss / seq_len\n",
    "    final_outer_loss.backward()\n",
    "    outer_optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Outer Loss: {final_outer_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
